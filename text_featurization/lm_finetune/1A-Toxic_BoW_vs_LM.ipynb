{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing Toxic Comments Using Pre-Trained Word Vectors and a Language Model's Encoder\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides an analysis of featurization methods for text. The central idea we examine is that we can represent text (words, phrases, and even entire sentences or paragraphs) as vectors. However, we'll see that some vector representations may provide more semantic information than others. \n",
    "\n",
    "## Pre-Trained Word Vectors\n",
    "\n",
    "As a first foray we featurize our data using publically available pre-trained word vectors. There are numerous word vectors available, the most common being [Word2Vec](https://code.google.com/archive/p/word2vec/), [GloVe](https://nlp.stanford.edu/projects/glove/), and [fasttext](https://github.com/facebookresearch/fastText/). We'll use the **GloVe** vectors trained on Wikipedia and Gigaword 5. \n",
    "\n",
    "Our input dataset contains a variable sequence of tokens (words), which we vectorize into a list of real-valued vectors. In order to use a machine learning model with such a representation we need to transform it into a fixed-vector representation. We can do this by many different aggregation schemes: sum/mean, max, min, etc. For this notebook we simply utilize unweighted averages of all the tokens, but you'll likely find that for some applications it may be more useful to consider max/min in addition, and concatenate multiple representations.\n",
    "\n",
    "\n",
    "![](https://image.slidesharecdn.com/starsem-170916142844/95/yejin-choi-2017-from-naive-physics-to-connotation-modeling-commonsense-in-frame-semantics-83-638.jpg?cb=1505572199)\n",
    "\n",
    "_image credit: Yejin Choi - 2017 - From Naive Physics to Connotation: Modeling Commonsense in Frame Semantics_\n",
    "\n",
    "_quote credit: Ray Mooney_\n",
    "\n",
    "\n",
    "## Language Model Encoders\n",
    "\n",
    "We'll then examine a more advanced method of featurizing our sequence of tokens. In particular, we'll use the encoder from a pre-trained language model. The encoder is a fixed-length vector representation that is typically the last hidden vector in a recurrent neural network trained for machine translation or language modeling.\n",
    "\n",
    "\n",
    "![](http://ruder.io/content/images/2018/07/lm_objective.png)\n",
    "\n",
    "_image credit: Seabstain Ruder and TheGradient: NLP's ImageNet moment has arrived_\n",
    "\n",
    "Our hope is that rather than naively aggregating our word vectors by their average representation, the last hidden layer will contain contextual information from the entire sequence of tokens.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:\n",
    "\n",
    "We import our dataset of comments to Wikipedia page-edits from our helper `load_data`. We'll also import a dictionary of GloVe vectors and a helper function for using it to lookup word vectors for our tokenized comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /anaconda/envs/tensorflow/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /anaconda/envs/tensorflow/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /anaconda/envs/tensorflow/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS=4\n",
    "\n",
    "from load_data import load_wiki_attacks, load_attack_encoded\n",
    "from load_data import tokenize, create_glove_lookup, download_glove\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "data_dir = pathlib.Path(\"/data\") / \"active-learning-workshop\" / \"text_featurization\" / \"data\"\n",
    "\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [spaCy](https://spacy.io/) library to tokenize our text, but aside from some prior data cleanup there's nothing fancy happening in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_src =  str(data_dir / \"glove.6B.300d.txt\")\n",
    "if not pathlib.Path(glove_src).exists():\n",
    "    download_glove(data_dir)\n",
    "glove_lookup = create_glove_lookup(glove_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is not creative . Those are the diction...</td>\n",
       "      <td>[  , This, is, not, creative, ., Those, are, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the term standard model is itself less NPO...</td>\n",
       "      <td>[    , the, term, standard, model, is, itself,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>[  , True, or, false, ,, the, situation, as, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next, maybe you could work on being less conde...</td>\n",
       "      <td>[Next, ,, maybe, you, could, work, on, being, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>[This, page, will, need, disambiguation, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Important note for all sysops There is a b...</td>\n",
       "      <td>[    , Important, note, for, all, sysops, Ther...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0    This is not creative . Those are the diction...   \n",
       "1      the term standard model is itself less NPO...   \n",
       "2    True or false, the situation as of March 200...   \n",
       "3  Next, maybe you could work on being less conde...   \n",
       "4                This page will need disambiguation.   \n",
       "5      Important note for all sysops There is a b...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [  , This, is, not, creative, ., Those, are, t...  \n",
       "1  [    , the, term, standard, model, is, itself,...  \n",
       "2  [  , True, or, false, ,, the, situation, as, o...  \n",
       "3  [Next, ,, maybe, you, could, work, on, being, ...  \n",
       "4        [This, page, will, need, disambiguation, .]  \n",
       "5  [    , Important, note, for, all, sysops, Ther...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = load_wiki_attacks(data_dir)\n",
    "toxic_df = tokenize(toxic_df, \"comment_text\")\n",
    "toxic_df.loc[:5, ['comment_text', \"tokens\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with GloVe:\n",
    "\n",
    "We can use our `glove_lookup` dictionary to vectorize all the tokens in our text. We apply the function to every token in our comment, and then take the average over all word vectors. Again, you should definitely consider other aggregation methods such as max/min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_df['glove_aggregate'] = toxic_df.tokens.apply(lambda x: np.mean([glove_lookup[v] for v in x], axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>glove_aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is not creative . Those are the diction...</td>\n",
       "      <td>[  , This, is, not, creative, ., Those, are, t...</td>\n",
       "      <td>[-0.1545063364709075, 0.06417014683847282, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the term standard model is itself less NPO...</td>\n",
       "      <td>[    , the, term, standard, model, is, itself,...</td>\n",
       "      <td>[-0.1303601454721643, 0.050615045016512684, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>[  , True, or, false, ,, the, situation, as, o...</td>\n",
       "      <td>[-0.012460944345166845, 0.06803597562600755, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next, maybe you could work on being less conde...</td>\n",
       "      <td>[Next, ,, maybe, you, could, work, on, being, ...</td>\n",
       "      <td>[-0.14296414278384567, 0.03661551114173733, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>[This, page, will, need, disambiguation, .]</td>\n",
       "      <td>[-0.48357245923669945, -0.0788922151379617, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Important note for all sysops There is a b...</td>\n",
       "      <td>[    , Important, note, for, all, sysops, Ther...</td>\n",
       "      <td>[-0.1576032897587098, 0.14894338008822366, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0    This is not creative . Those are the diction...   \n",
       "1      the term standard model is itself less NPO...   \n",
       "2    True or false, the situation as of March 200...   \n",
       "3  Next, maybe you could work on being less conde...   \n",
       "4                This page will need disambiguation.   \n",
       "5      Important note for all sysops There is a b...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [  , This, is, not, creative, ., Those, are, t...   \n",
       "1  [    , the, term, standard, model, is, itself,...   \n",
       "2  [  , True, or, false, ,, the, situation, as, o...   \n",
       "3  [Next, ,, maybe, you, could, work, on, being, ...   \n",
       "4        [This, page, will, need, disambiguation, .]   \n",
       "5  [    , Important, note, for, all, sysops, Ther...   \n",
       "\n",
       "                                     glove_aggregate  \n",
       "0  [-0.1545063364709075, 0.06417014683847282, 0.0...  \n",
       "1  [-0.1303601454721643, 0.050615045016512684, 0....  \n",
       "2  [-0.012460944345166845, 0.06803597562600755, 0...  \n",
       "3  [-0.14296414278384567, 0.03661551114173733, -0...  \n",
       "4  [-0.48357245923669945, -0.0788922151379617, -0...  \n",
       "5  [-0.1576032897587098, 0.14894338008822366, -0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df.loc[:5, [\"comment_text\", \"tokens\", \"glove_aggregate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model \n",
    "\n",
    "Our language model encoder utilizes pre-trained language models hosted on [TensorFlow Hub](https://www.tensorflow.org/hub/modules/text). \n",
    "\n",
    "Our helper script `encoder.py` provides a simple class entitled `encoder` with methods for encoding text using three different encoder models: [ELMO](http://www.aclweb.org/anthology/N18-1202), [USE](https://arxiv.org/pdf/1803.11175.pdf), and [NNLM](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Imports:\n",
    "\n",
    "The class is a bit verbose for readability, but it's conceptually very simple. We load the pre-trained module, which defines a static computational graph with the learned weights from the language model on it's dataset. We initialize this computational graph into a Keras session, which we can then use for fine-tuning or for featurizing an input sequence by computing a forward pass of the computational graph. Note, we could have also just used `tensorflow` directly to do the model building and training, but Keras has some helpful utilities for data min-batching and pre-fetching that makes this very easy (at the cost of some incompatibilities: [issues with fine-tuning may arise](https://groups.google.com/a/tensorflow.org/forum/#!topic/hub/Y4AdAM7HpX0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from encoder import encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "??encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurized Dataset\n",
    "\n",
    "Here's an example usage of converting the `comment_text` into a fixed sequence using our encoder and the **Universal Sentence Encoder**:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "use_encoder = encoder(model=\"use\")\n",
    "featurizer = use_encoder.transform_model()\n",
    "featurizer.summary()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    transformed_review = featurizer.predict(toxic_df.comment_text.values, batch_size=64)\n",
    "```\n",
    "\n",
    "This operation will take some time, ~1.5 hours on a machine with 16 cores. We have a pre-featurized version of this dataset already saved for you, which you can download using our helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_attacks = load_attack_encoded(data_dir)\n",
    "toxic_df['encoded_comment'] = encoded_attacks.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>encoded_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is not creative . Those are the diction...</td>\n",
       "      <td>[0.026781896, -0.05754256, 0.033774074, 0.0097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the term standard model is itself less NPO...</td>\n",
       "      <td>[0.011424046, -0.009576778000000001, -0.026437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>[0.00041413374, 0.08557465, 0.024096673, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next, maybe you could work on being less conde...</td>\n",
       "      <td>[0.058229163, 0.048170675, -0.054312646, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>[0.05511004, 0.017830834, -0.08593257, -0.0343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Important note for all sysops There is a b...</td>\n",
       "      <td>[0.07102389, 0.029018747, -0.04301559, -0.0764...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0    This is not creative . Those are the diction...   \n",
       "1      the term standard model is itself less NPO...   \n",
       "2    True or false, the situation as of March 200...   \n",
       "3  Next, maybe you could work on being less conde...   \n",
       "4                This page will need disambiguation.   \n",
       "5      Important note for all sysops There is a b...   \n",
       "\n",
       "                                     encoded_comment  \n",
       "0  [0.026781896, -0.05754256, 0.033774074, 0.0097...  \n",
       "1  [0.011424046, -0.009576778000000001, -0.026437...  \n",
       "2  [0.00041413374, 0.08557465, 0.024096673, -0.09...  \n",
       "3  [0.058229163, 0.048170675, -0.054312646, 0.029...  \n",
       "4  [0.05511004, 0.017830834, -0.08593257, -0.0343...  \n",
       "5  [0.07102389, 0.029018747, -0.04301559, -0.0764...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df.loc[:5, ['comment_text', 'encoded_comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "How do these features compare on discrimaniting between toxic / non-toxic comments? Let's put them in a raceoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "train_sizes = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "# estimator = GaussianNB()\n",
    "# estimator = RandomForestClassifier()\n",
    "\n",
    "def featurize(df=toxic_df):\n",
    "\n",
    "    labels = np.concatenate(lb.fit_transform(df.is_attack.values))\n",
    "    glove_features = np.vstack(df.glove_aggregate.values)\n",
    "    use_features = np.vstack(df.encoded_comment.values)\n",
    "\n",
    "    return labels, glove_features, use_features\n",
    "\n",
    "labels, glove_features, use_features = featurize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves:\n",
    "\n",
    "Learning curves allows us to visualize the performance of the system as a function of the amount of examples it's seen. We first create learning curves using the `glove_features`, and then we create learning curves of the `encoded_features`. We plot them together so we can compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 455 ms, total: 17.9 s\n",
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g_train_sizes, g_train_scores, g_test_scores = learning_curve(estimator=estimator, \n",
    "                                                              X=glove_features,\n",
    "                                                              y=labels, \n",
    "                                                              scoring=make_scorer(roc_auc_score),\n",
    "                                                              n_jobs=NUM_WORKERS, train_sizes=train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 627 ms, total: 29.6 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e_train_sizes, e_train_scores, e_test_scores = learning_curve(estimator=estimator, \n",
    "                                                              X=use_features,\n",
    "                                                              y=labels, \n",
    "                                                              scoring=make_scorer(roc_auc_score),\n",
    "                                                              n_jobs=NUM_WORKERS, train_sizes=train_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We used AUC as our scoring criteria, but you could also use accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3a844bd278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "results_df = pd.DataFrame({\"train_perc\": train_sizes,\n",
    "                           \"bow_auc\": np.mean(g_test_scores, axis=1),\n",
    "                           \"encoder_auc\": np.mean(e_test_scores, axis=1)})\n",
    "\n",
    "sns.lineplot(x=\"train_perc\", y=\"AUC\", hue=\"features\", \n",
    "             data=results_df.melt(\"train_perc\", var_name=\"features\", value_name=\"AUC\"), \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder features outperform the bag-of-words (BoW) glove vectors at every level of training data experience. While a more careful aggregation procedure of the word vectors would have done much better (in fact, there's good evidence that a thoughtful weighted-average can be [very hard to beat](https://openreview.net/forum?id=SyK00v5xx) on many discriminative tasks), the main point of this analysis is that using pre-trained encoders can basically be a drop-in replacement for word vectors for many applications and give significant gains, _modulo_ additional computation time to featurize the dataset (the BoW approach uses a lookup to compute features, which is very fast, whereas the encoder approach requires a full forward pass through a complicated recurrent neural network, which are inherently sequential (this is why there is a greater push towards [feed-forward architectures for language modeling](https://blog.openai.com/language-unsupervised/), which can be much faster during training and evaluation time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis __WARNING: FOUL LANGUAGE AHEAD__:\n",
    "\n",
    "Let's see some examples of where our model using language model features outperformed our BoW model. We'll be a bit more fair to both models this time and do a quick grid search to find a well-optimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 1.3 s, total: 28.7 s\n",
      "Wall time: 28.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_df = toxic_df.loc[:,['is_attack', 'comment_text', 'glove_aggregate', 'encoded_comment']]\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "train_df, test_df = train_test_split(model_df, train_size=0.75, random_state=12)\n",
    "\n",
    "def cv_predict_eval():\n",
    "\n",
    "#     cv = GridSearchCV(RandomForestClassifier(),\n",
    "#                      param_grid={\n",
    "#                          'n_estimators': [10, 100],\n",
    "#                          'max_features': ['sqrt', 'log2'],\n",
    "#                          'max_depth': [3, 5, None]\n",
    "#                      }, \n",
    "#                       refit=True, \n",
    "#                       n_jobs=NUM_WORKERS)\n",
    "\n",
    "    cv = LogisticRegression()\n",
    "\n",
    "    labels, glove_features, use_features = featurize(train_df)\n",
    "    labels_test, glove_test, use_test = featurize(test_df)\n",
    "\n",
    "    glove_fit = cv.fit(glove_features, labels)\n",
    "    glove_hat = glove_fit.predict(glove_test)\n",
    "    use_fit = cv.fit(use_features, labels)\n",
    "    use_hat = use_fit.predict(use_test)\n",
    "\n",
    "    results_df = test_df\n",
    "    results_df['use_pred'] = use_hat\n",
    "    results_df['glove_pred'] = glove_hat\n",
    "\n",
    "    return results_df\n",
    "\n",
    "results_df = cv_predict_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where BoW-GloVe Fails and the Encoder Succeeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105512</th>\n",
       "      <td>thanks a lot man, you dont know how long thats...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39670</th>\n",
       "      <td>You re completely wrong. He did.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87075</th>\n",
       "      <td>He was a real good composser</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77299</th>\n",
       "      <td>im half crazy figure out which side...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9532</th>\n",
       "      <td>hunk of rock orbiting the Sun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87038</th>\n",
       "      <td>stop with the warnings ill just be back lol...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57295</th>\n",
       "      <td>i love robert barrington</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70225</th>\n",
       "      <td>Total sperglords.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111135</th>\n",
       "      <td>Imagine defending a professional paedophile ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69583</th>\n",
       "      <td>NO I HATE IT BECAUSE YOU DELETE EVERYTHING</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>Image Skyscrapercompare.svg IS INCORRECT AND...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25805</th>\n",
       "      <td>Bold textItalic textokay then this is just a s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52624</th>\n",
       "      <td>BIGGER WINNER THAN YOU....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>A cruiser is a type of battleship, you know.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60775</th>\n",
       "      <td>Canadian  Why is he listed as a Canadian Am...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87782</th>\n",
       "      <td>former Netherlands Antilles, the</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60535</th>\n",
       "      <td>ha ha ha . ha ha ha ha ha . ha ha ha haha a h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>REDIRECT Talk Smyrna High School Tennessee</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44206</th>\n",
       "      <td>mamas boy mamas boy mamas boy mamas boymamas b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103405</th>\n",
       "      <td>Did you walk around for the entire event with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>Eh Girlvinyl man Had me fooled.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88354</th>\n",
       "      <td>calm your self boy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>non mammal and highly carnivorous.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108311</th>\n",
       "      <td>gonna do about it  Yeah ee yeah, yeah ee  Shak...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73311</th>\n",
       "      <td>You could do worse.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50225</th>\n",
       "      <td>hello clown  Rust never sleeps</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83288</th>\n",
       "      <td>No. DO IT THROUGH THE PROPER CHANNELS.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57827</th>\n",
       "      <td>jews  the only people that do conspiring is...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47355</th>\n",
       "      <td>hey wats up people</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18736</th>\n",
       "      <td>Strong disagree Just because a poodle is a d...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22913</th>\n",
       "      <td>page and your dungeons and dragons</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72017</th>\n",
       "      <td>hi terry   how are ya koeckritz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78311</th>\n",
       "      <td>Can you delete this vandalism</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36123</th>\n",
       "      <td>VideoClip2 SalsaBalroomDance Country TBA Semi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>In Soviet Russia, vodka drinks you.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95987</th>\n",
       "      <td>Skinks Scincidae  Family</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75930</th>\n",
       "      <td>CBC Languages act called Quebec Nazi Act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>Was Dick Emery jewish</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>This is unhelpful. You wish a unilateral ri...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68224</th>\n",
       "      <td>Yup..That sums up..</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68817</th>\n",
       "      <td>Another administator impersonator.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>A holiday wish to a Rhobite   Happy Thanksg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111498</th>\n",
       "      <td>HELLO Some random guy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35430</th>\n",
       "      <td>why do you keep reverting my edits</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28687</th>\n",
       "      <td>you do know that you are a dupe, right just ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46534</th>\n",
       "      <td>I am tired of his insults.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>good sir. And God blessyou</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106268</th>\n",
       "      <td>Not controversial. He is a convicted felon fo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23355</th>\n",
       "      <td>To LongHair etu brute see Images from Scorp...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68390</th>\n",
       "      <td>so stop reverting the damn deletion</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>L2 SPELL RESPONSE SON BILLY MAYES OUT AGAIN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50092</th>\n",
       "      <td>Smiles</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77442</th>\n",
       "      <td>why you cleen my mesage maybe i help you. gi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>ANYTHING YOU SAY CAN AND WILL BE USED AGAINST...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107469</th>\n",
       "      <td>IR medication guide and the</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97642</th>\n",
       "      <td>and Germans redirets to German people</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59456</th>\n",
       "      <td>i am sorry for vandalising i promise not to do...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32836</th>\n",
       "      <td>some white people considered black people to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102777</th>\n",
       "      <td>Are you a racist Do you have something against...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16627</th>\n",
       "      <td>for a lying phony, Tijuana Brass</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  is_attack\n",
       "105512  thanks a lot man, you dont know how long thats...      False\n",
       "39670                    You re completely wrong. He did.      False\n",
       "87075                       He was a real good composser       False\n",
       "77299              im half crazy figure out which side...      False\n",
       "9532                        hunk of rock orbiting the Sun      False\n",
       "87038      stop with the warnings ill just be back lol...      False\n",
       "57295                           i love robert barrington       False\n",
       "70225                                   Total sperglords.      False\n",
       "111135    Imagine defending a professional paedophile ...      False\n",
       "69583          NO I HATE IT BECAUSE YOU DELETE EVERYTHING      False\n",
       "49457     Image Skyscrapercompare.svg IS INCORRECT AND...      False\n",
       "25805   Bold textItalic textokay then this is just a s...      False\n",
       "52624                          BIGGER WINNER THAN YOU....      False\n",
       "9462         A cruiser is a type of battleship, you know.      False\n",
       "60775      Canadian  Why is he listed as a Canadian Am...      False\n",
       "87782                    former Netherlands Antilles, the      False\n",
       "60535    ha ha ha . ha ha ha ha ha . ha ha ha haha a h...      False\n",
       "20487         REDIRECT Talk Smyrna High School Tennessee       False\n",
       "44206   mamas boy mamas boy mamas boy mamas boymamas b...      False\n",
       "103405  Did you walk around for the entire event with ...      False\n",
       "3167                      Eh Girlvinyl man Had me fooled.      False\n",
       "88354                                  calm your self boy      False\n",
       "5246                   non mammal and highly carnivorous.      False\n",
       "108311  gonna do about it  Yeah ee yeah, yeah ee  Shak...      False\n",
       "73311                                 You could do worse.      False\n",
       "50225                      hello clown  Rust never sleeps      False\n",
       "83288              No. DO IT THROUGH THE PROPER CHANNELS.      False\n",
       "57827      jews  the only people that do conspiring is...      False\n",
       "47355                              hey wats up people          False\n",
       "18736     Strong disagree Just because a poodle is a d...      False\n",
       "...                                                   ...        ...\n",
       "22913                  page and your dungeons and dragons      False\n",
       "72017                    hi terry   how are ya koeckritz       False\n",
       "78311                      Can you delete this vandalism       False\n",
       "36123    VideoClip2 SalsaBalroomDance Country TBA Semi...      False\n",
       "18362                In Soviet Russia, vodka drinks you.       False\n",
       "95987                           Skinks Scincidae  Family       False\n",
       "75930           CBC Languages act called Quebec Nazi Act       False\n",
       "3939                               Was Dick Emery jewish       False\n",
       "1553       This is unhelpful. You wish a unilateral ri...      False\n",
       "68224                                Yup..That sums up..       False\n",
       "68817                Another administator impersonator.        False\n",
       "4589       A holiday wish to a Rhobite   Happy Thanksg...      False\n",
       "111498                              HELLO Some random guy      False\n",
       "35430                why do you keep reverting my edits        False\n",
       "28687     you do know that you are a dupe, right just ...      False\n",
       "46534                        I am tired of his insults.        False\n",
       "3075                           good sir. And God blessyou      False\n",
       "106268   Not controversial. He is a convicted felon fo...      False\n",
       "23355      To LongHair etu brute see Images from Scorp...      False\n",
       "68390               so stop reverting the damn deletion        False\n",
       "44897        L2 SPELL RESPONSE SON BILLY MAYES OUT AGAIN       False\n",
       "50092                                             Smiles       False\n",
       "77442     why you cleen my mesage maybe i help you. gi...      False\n",
       "3032     ANYTHING YOU SAY CAN AND WILL BE USED AGAINST...      False\n",
       "107469                        IR medication guide and the      False\n",
       "97642               and Germans redirets to German people      False\n",
       "59456   i am sorry for vandalising i promise not to do...      False\n",
       "32836    some white people considered black people to ...      False\n",
       "102777  Are you a racist Do you have something against...      False\n",
       "16627                 for a lying phony, Tijuana Brass         False\n",
       "\n",
       "[485 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[(results_df[\"is_attack\"] == results_df[\"use_pred\"]) & \n",
    "               (results_df[\"is_attack\"] != results_df[\"glove_pred\"]) & \n",
    "               (results_df[\"is_attack\"] == False), \n",
    "               [\"comment_text\", \"is_attack\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i am sorry for vandalising i promise not to do it anymore'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[[59456], \"comment_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thanks a lot man, you dont know how long thats been fuckin with my head  '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[[105512], \"comment_text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's unfortunately pretty challenging to find any civil discussion on online forums. In the example highlighted above our BoW approach predicted the comment to be an attack, whereas the encoder correctly predicted it as benign. The prevalence of terms such \"dumb\", \"sorry\" _bias_ the average word vector to a representation that is more likely to be an attack than a nice comment, whereas the language model is able to encode the sequence of representations more accurately. A more acute example of this phenomena arises with swear words (ommitted here, but see for example record index `[105512]` for an example where the single occurrence of a curse word causes the BoW classifier to misclassify the sentiment dramatically (but the encoder gets it right). This also arises frequently in the use of **negation** in sentiment analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
